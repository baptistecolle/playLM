{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gymnasium\n",
      "  Downloading gymnasium-0.28.1-py3-none-any.whl (925 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m925.5/925.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting farama-notifications>=0.0.1\n",
      "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/alves/anaconda3/lib/python3.10/site-packages (from gymnasium) (2.0.0)\n",
      "Collecting jax-jumpy>=1.0.0\n",
      "  Downloading jax_jumpy-1.0.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /Users/alves/anaconda3/lib/python3.10/site-packages (from gymnasium) (4.6.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/alves/anaconda3/lib/python3.10/site-packages (from gymnasium) (1.23.5)\n",
      "Installing collected packages: farama-notifications, jax-jumpy, gymnasium\n",
      "Successfully installed farama-notifications-0.0.4 gymnasium-0.28.1 jax-jumpy-1.0.0\n",
      "Requirement already satisfied: matplotlib in /Users/alves/anaconda3/lib/python3.10/site-packages (3.7.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/alves/anaconda3/lib/python3.10/site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/alves/anaconda3/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/alves/anaconda3/lib/python3.10/site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/alves/anaconda3/lib/python3.10/site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/alves/anaconda3/lib/python3.10/site-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/alves/anaconda3/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/alves/anaconda3/lib/python3.10/site-packages (from matplotlib) (22.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/alves/anaconda3/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/alves/anaconda3/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /Users/alves/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# launch adventure environment with human rendering\n",
    "env = gym.make(\"FrozenLake-v1\")\n",
    "env.reset()\n",
    "\n",
    "number_of_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_cpp import Llama\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "class LLM_Agent:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.llm = Llama(model_path=\"../model/wizardLM-7B.ggmlv3.q4_1.bin\", logits_all=True)\n",
    "\n",
    "        # RL specific variables\n",
    "        self.observations = []\n",
    "        self.rewards = []\n",
    "\n",
    "\n",
    "        self.memory = [] # extract previous epsiodes from game\n",
    "        self.belief = [] # extract rules from game\n",
    "\n",
    "    def set_action_space(self, action_space):\n",
    "        self.action_space = action_space\n",
    "        self.text_action_space = ', '.join(f\"'{w}'\" for w in action_space)\n",
    "        print(\"action space: \", self.action_space)\n",
    "\n",
    "    def get_action_prompt(self):\n",
    "        prompt = (\n",
    "            f\"{self.character_prompt}\"\n",
    "            f\"This is the current state of the board {self.observations[-1]}. \"\n",
    "            f\"You can use the following actions: {self.text_action_space}. \"\n",
    "            f\"Please output one of the possible actions. \"\n",
    "            f\"If you are unsure, please output an action as you are learning how to use the controllers of this video game. \"\n",
    "            f\"The selected action is: \"\n",
    "        )\n",
    "        return prompt\n",
    "\n",
    "    def set_character_prompt(self, character_prompt):\n",
    "        self.character_prompt = character_prompt\n",
    "\n",
    "    def generate(self, prompt):\n",
    "        return self.llm(f\"\"\"{prompt}\"\"\", echo=True)\n",
    "    \n",
    "    def save_observation(self, observation):\n",
    "        self.observations.append(observation)\n",
    "\n",
    "    def save_reward(self, reward):\n",
    "        self.rewards.append(reward)\n",
    "    \n",
    "    def generate_action(self, debug=False):\n",
    "        print(\"generate_action\")\n",
    "\n",
    "        prompt = self.get_action_prompt()\n",
    "        print(f\"get_action_prompt: {prompt}\")\n",
    "\n",
    "        # TODO check actions are valid\n",
    "        output = self.generate(prompt)\n",
    "        print(f\"generated output: {output}\")\n",
    "        \n",
    "        generated_text = output['choices'][0]['text']\n",
    "        print(f\"generated text: {generated_text}\")\n",
    "        \n",
    "        # Find the direction chosen by the LLM_agent\n",
    "        generated_direction = re.search(\"'([^']+)'\", generated_text)\n",
    "        print(f\"Generated direction: {generated_direction.group(1)}\")\n",
    "\n",
    "\n",
    "        # TODO beam search would be better here or using raw logits\n",
    "        \n",
    "\n",
    "        # for all actions in action space check at which index it appears in the generated text\n",
    "        # the action with the lowest index is the action we want to take\n",
    "        text_index = 1000\n",
    "        action_number = -1\n",
    "        times_found = -1\n",
    "        print(\"Searching for action in generated text\")\n",
    "        for i, current_action in enumerate(self.action_space):\n",
    "            # TODO - THSI is not working - make it look properly into the generated text\n",
    "            action_index = generated_text.find(current_action)\n",
    "            print(f\"action: {current_action}, index: {action_index}\")\n",
    "            if action_index != -1 and action_index < text_index:\n",
    "                times_found += 1\n",
    "                print(f\"looking for action {current_action} in generated text \")\n",
    "                print(f\"action found {times_found} times\")\n",
    "                # text_index = action_index\n",
    "                # action_number = i\n",
    "\n",
    "\n",
    "            # we want to skip the first occurence of the action\n",
    "            # since the first time it is in the text is when we are giving instructions to the LLM\n",
    "            if times_found >= 1:\n",
    "                text_index = action_index\n",
    "                action_number = i\n",
    "               \n",
    "                \n",
    "\n",
    "        if action_number == -1:\n",
    "            # raise Exception(\"No action found in generated text\")\n",
    "            # print warning in red\n",
    "            print(\"\\033[91mNo action found in generated text\\033[0m\")\n",
    "            # randomly select action\n",
    "            action_number = np.random.randint(0, len(self.action_space))\n",
    "        \n",
    "        return action_number\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some random notes / ideas\n",
    "\n",
    "# multiple model controller, critic\n",
    "# queue and planning\n",
    "# long term memory \n",
    "# react \n",
    "# https://github.com/luca-medeiros/lang-segment-anything\n",
    "# autonomous agents text us back if does know what to do and learn from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action space:  ['LEFT', 'RIGHT', 'DOWN', 'UP']\n",
      "action space:  ['LEFT', 'RIGHT', 'DOWN', 'UP']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from ../model/wizardLM-7B.ggmlv3.q4_1.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32001\n",
      "llama_model_load_internal: n_ctx      = 512\n",
      "llama_model_load_internal: n_embd     = 4096\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 32\n",
      "llama_model_load_internal: n_layer    = 32\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: ftype      = 3 (mostly Q4_1)\n",
      "llama_model_load_internal: n_ff       = 11008\n",
      "llama_model_load_internal: n_parts    = 1\n",
      "llama_model_load_internal: model size = 7B\n",
      "llama_model_load_internal: ggml ctx size =    0.07 MB\n",
      "llama_model_load_internal: mem required  = 5809.34 MB (+ 1026.00 MB per state)\n",
      ".\n",
      "AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | \n",
      "llama_init_from_file: kv self size  =  256.00 MB\n"
     ]
    }
   ],
   "source": [
    "# Your a video game player, your goal is to get the key and get out of the dungeon\n",
    "\n",
    "agent = LLM_Agent()\n",
    "\n",
    "# TODO check if this actually does anything\n",
    "# env.action_space\n",
    "\n",
    "action_space = ['LEFT', 'RIGHT', 'DOWN', 'UP']\n",
    "# action_space = env.action_space.seed(0)\n",
    "# action_space = []\n",
    "\n",
    "# for i in range(env.action_space.n):\n",
    "#     print(i)\n",
    "#     action_space.append(env.action_space.seed(i)[0])\n",
    "#     print(action_space)\n",
    "\n",
    "\n",
    "print(\"action space: \", action_space)\n",
    "\n",
    "# how can we get the agent to learn the action space\n",
    "agent.set_action_space(action_space=action_space)\n",
    "\n",
    "agent.set_character_prompt(\"You are a video game player.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation: (0, {'prob': 1})\n",
      "episode_reward: 0\n",
      "=> TIMESTAMP [0]; EPISODE [0]<=\n",
      "position: 0\n",
      "saved observation: you are in position 0\n",
      "generate_action\n",
      "get_action_prompt: You are a video game player.This is the current state of the board you are in position 0. This is the start of the game.. You can use the following actions: 'LEFT', 'RIGHT', 'DOWN', 'UP'. Please output one of the possible actions. If you are unsure, please output an action as you are learning how to use the controllers of this video game. The selected action is: \n",
      "generated output: {'id': 'cmpl-915d5aac-0675-4dc1-86aa-877eba8f69a1', 'object': 'text_completion', 'created': 1686001224, 'model': '../model/wizardLM-7B.ggmlv3.q4_1.bin', 'choices': [{'text': \"You are a video game player.This is the current state of the board you are in position 0. This is the start of the game.. You can use the following actions: 'LEFT', 'RIGHT', 'DOWN', 'UP'. Please output one of the possible actions. If you are unsure, please output an action as you are learning how to use the controllers of this video game. The selected action is: \\n'LEFT'\", 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 90, 'completion_tokens': 4, 'total_tokens': 94}}\n",
      "generated text: You are a video game player.This is the current state of the board you are in position 0. This is the start of the game.. You can use the following actions: 'LEFT', 'RIGHT', 'DOWN', 'UP'. Please output one of the possible actions. If you are unsure, please output an action as you are learning how to use the controllers of this video game. The selected action is: \n",
      "'LEFT'\n",
      "Generated direction: LEFT\n",
      "Searching for action in generated text\n",
      "action: LEFT, index: 158\n",
      "action: RIGHT, index: 166\n",
      "action: DOWN, index: 175\n",
      "action: UP, index: 183\n",
      "selected action 3\n",
      "GENERATED ACTION:  3\n",
      "RENEDERED ACTION:  None\n",
      "--------------------\n",
      "obs: 0\n",
      "reward: 0.0\n",
      "terminated: False\n",
      "truncated: False\n",
      "info: {'prob': 0.3333333333333333}\n",
      "--------------------\n",
      "=> TIMESTAMP [1]; EPISODE [0]<=\n",
      "position: 0\n",
      "saved observation: you are in position 0\n",
      "generate_action\n",
      "get_action_prompt: You are a video game player.This is the current state of the board you are still in position 0. You did not move. Your last action was 3.. You can use the following actions: 'LEFT', 'RIGHT', 'DOWN', 'UP'. Please output one of the possible actions. If you are unsure, please output an action as you are learning how to use the controllers of this video game. The selected action is: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/alves/anaconda3/lib/python3.10/site-packages/gymnasium/envs/toy_text/frozen_lake.py:328: UserWarning: \u001b[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym.make(\"FrozenLake-v1\", render_mode=\"rgb_array\")\u001b[0m\n",
      "  gym.logger.warn(\n",
      "llama_print_timings:        load time = 14337.97 ms\n",
      "llama_print_timings:      sample time =     3.58 ms /     5 runs   (    0.72 ms per token)\n",
      "llama_print_timings: prompt eval time = 14337.91 ms /    90 tokens (  159.31 ms per token)\n",
      "llama_print_timings:        eval time = 33327.29 ms /     4 runs   ( 8331.82 ms per token)\n",
      "llama_print_timings:       total time = 47896.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated output: {'id': 'cmpl-bbfcfa09-f85c-47f8-943a-9c8d96aced4c', 'object': 'text_completion', 'created': 1686001272, 'model': '../model/wizardLM-7B.ggmlv3.q4_1.bin', 'choices': [{'text': \"You are a video game player.This is the current state of the board you are still in position 0. You did not move. Your last action was 3.. You can use the following actions: 'LEFT', 'RIGHT', 'DOWN', 'UP'. Please output one of the possible actions. If you are unsure, please output an action as you are learning how to use the controllers of this video game. The selected action is: \\n'LEFT'\", 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 95, 'completion_tokens': 4, 'total_tokens': 99}}\n",
      "generated text: You are a video game player.This is the current state of the board you are still in position 0. You did not move. Your last action was 3.. You can use the following actions: 'LEFT', 'RIGHT', 'DOWN', 'UP'. Please output one of the possible actions. If you are unsure, please output an action as you are learning how to use the controllers of this video game. The selected action is: \n",
      "'LEFT'\n",
      "Generated direction: LEFT\n",
      "Searching for action in generated text\n",
      "action: LEFT, index: 175\n",
      "action: RIGHT, index: 183\n",
      "action: DOWN, index: 192\n",
      "action: UP, index: 200\n",
      "selected action 3\n",
      "GENERATED ACTION:  3\n",
      "RENEDERED ACTION:  None\n",
      "--------------------\n",
      "obs: 0\n",
      "reward: 0.0\n",
      "terminated: False\n",
      "truncated: False\n",
      "info: {'prob': 0.3333333333333333}\n",
      "--------------------\n",
      "=> TIMESTAMP [2]; EPISODE [0]<=\n",
      "position: 0\n",
      "saved observation: you are in position 0\n",
      "generate_action\n",
      "get_action_prompt: You are a video game player.This is the current state of the board you are still in position 0. You did not move. Your last action was 3.. You can use the following actions: 'LEFT', 'RIGHT', 'DOWN', 'UP'. Please output one of the possible actions. If you are unsure, please output an action as you are learning how to use the controllers of this video game. The selected action is: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time = 14337.97 ms\n",
      "llama_print_timings:      sample time =     3.65 ms /     5 runs   (    0.73 ms per token)\n",
      "llama_print_timings: prompt eval time = 14931.11 ms /    77 tokens (  193.91 ms per token)\n",
      "llama_print_timings:        eval time = 33473.50 ms /     4 runs   ( 8368.37 ms per token)\n",
      "llama_print_timings:       total time = 48626.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time = 14337.97 ms\n",
      "llama_print_timings:      sample time =     7.75 ms /    10 runs   (    0.77 ms per token)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token)\n",
      "llama_print_timings:        eval time = 82650.26 ms /    10 runs   ( 8265.03 ms per token)\n",
      "llama_print_timings:       total time = 82747.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated output: {'id': 'cmpl-f314384d-cb72-40fb-a1ad-276ebfd8b307', 'object': 'text_completion', 'created': 1686001321, 'model': '../model/wizardLM-7B.ggmlv3.q4_1.bin', 'choices': [{'text': \"You are a video game player.This is the current state of the board you are still in position 0. You did not move. Your last action was 3.. You can use the following actions: 'LEFT', 'RIGHT', 'DOWN', 'UP'. Please output one of the possible actions. If you are unsure, please output an action as you are learning how to use the controllers of this video game. The selected action is: \\n```\\nYou selected LEFT.\\n```\", 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 95, 'completion_tokens': 9, 'total_tokens': 104}}\n",
      "generated text: You are a video game player.This is the current state of the board you are still in position 0. You did not move. Your last action was 3.. You can use the following actions: 'LEFT', 'RIGHT', 'DOWN', 'UP'. Please output one of the possible actions. If you are unsure, please output an action as you are learning how to use the controllers of this video game. The selected action is: \n",
      "```\n",
      "You selected LEFT.\n",
      "```\n",
      "Generated direction: LEFT\n",
      "Searching for action in generated text\n",
      "action: LEFT, index: 175\n",
      "action: RIGHT, index: 183\n",
      "action: DOWN, index: 192\n",
      "action: UP, index: 200\n",
      "selected action 3\n",
      "GENERATED ACTION:  3\n",
      "RENEDERED ACTION:  None\n",
      "--------------------\n",
      "obs: 0\n",
      "reward: 0.0\n",
      "terminated: False\n",
      "truncated: False\n",
      "info: {'prob': 0.3333333333333333}\n",
      "--------------------\n",
      "=> TIMESTAMP [3]; EPISODE [0]<=\n",
      "position: 0\n",
      "saved observation: you are in position 0\n",
      "generate_action\n",
      "get_action_prompt: You are a video game player.This is the current state of the board you are still in position 0. You did not move. Your last action was 3.. You can use the following actions: 'LEFT', 'RIGHT', 'DOWN', 'UP'. Please output one of the possible actions. If you are unsure, please output an action as you are learning how to use the controllers of this video game. The selected action is: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msaved observation: you are in position \u001b[39m\u001b[39m{\u001b[39;00mposition\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[39m# generate action\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m action \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mgenerate_action(debug\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     41\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mselected action\u001b[39m\u001b[39m\"\u001b[39m, action)\n\u001b[1;32m     43\u001b[0m \u001b[39m# take action\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[39m# Within the game board state\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39m# \u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 54\u001b[0m, in \u001b[0;36mLLM_Agent.generate_action\u001b[0;34m(self, debug)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mget_action_prompt: \u001b[39m\u001b[39m{\u001b[39;00mprompt\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[39m# TODO check actions are valid\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt)\n\u001b[1;32m     55\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgenerated output: \u001b[39m\u001b[39m{\u001b[39;00moutput\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m generated_text \u001b[39m=\u001b[39m output[\u001b[39m'\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[19], line 39\u001b[0m, in \u001b[0;36mLLM_Agent.generate\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate\u001b[39m(\u001b[39mself\u001b[39m, prompt):\n\u001b[0;32m---> 39\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm(\u001b[39mf\u001b[39;49m\u001b[39m\"\"\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mprompt\u001b[39m}\u001b[39;49;00m\u001b[39m\"\"\"\u001b[39;49m, echo\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/llama_cpp/llama.py:1185\u001b[0m, in \u001b[0;36mLlama.__call__\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[1;32m   1141\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1142\u001b[0m     prompt: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1161\u001b[0m     logits_processor: Optional[LogitsProcessorList] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1162\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[Completion, Iterator[CompletionChunk]]:\n\u001b[1;32m   1163\u001b[0m     \u001b[39m\"\"\"Generate text from a prompt.\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m \n\u001b[1;32m   1165\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[39m        Response object containing the generated text.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1185\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_completion(\n\u001b[1;32m   1186\u001b[0m         prompt\u001b[39m=\u001b[39;49mprompt,\n\u001b[1;32m   1187\u001b[0m         suffix\u001b[39m=\u001b[39;49msuffix,\n\u001b[1;32m   1188\u001b[0m         max_tokens\u001b[39m=\u001b[39;49mmax_tokens,\n\u001b[1;32m   1189\u001b[0m         temperature\u001b[39m=\u001b[39;49mtemperature,\n\u001b[1;32m   1190\u001b[0m         top_p\u001b[39m=\u001b[39;49mtop_p,\n\u001b[1;32m   1191\u001b[0m         logprobs\u001b[39m=\u001b[39;49mlogprobs,\n\u001b[1;32m   1192\u001b[0m         echo\u001b[39m=\u001b[39;49mecho,\n\u001b[1;32m   1193\u001b[0m         stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m   1194\u001b[0m         frequency_penalty\u001b[39m=\u001b[39;49mfrequency_penalty,\n\u001b[1;32m   1195\u001b[0m         presence_penalty\u001b[39m=\u001b[39;49mpresence_penalty,\n\u001b[1;32m   1196\u001b[0m         repeat_penalty\u001b[39m=\u001b[39;49mrepeat_penalty,\n\u001b[1;32m   1197\u001b[0m         top_k\u001b[39m=\u001b[39;49mtop_k,\n\u001b[1;32m   1198\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m   1199\u001b[0m         tfs_z\u001b[39m=\u001b[39;49mtfs_z,\n\u001b[1;32m   1200\u001b[0m         mirostat_mode\u001b[39m=\u001b[39;49mmirostat_mode,\n\u001b[1;32m   1201\u001b[0m         mirostat_tau\u001b[39m=\u001b[39;49mmirostat_tau,\n\u001b[1;32m   1202\u001b[0m         mirostat_eta\u001b[39m=\u001b[39;49mmirostat_eta,\n\u001b[1;32m   1203\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1204\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[1;32m   1205\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[1;32m   1206\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/llama_cpp/llama.py:1137\u001b[0m, in \u001b[0;36mLlama.create_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     chunks: Iterator[CompletionChunk] \u001b[39m=\u001b[39m completion_or_chunks\n\u001b[1;32m   1136\u001b[0m     \u001b[39mreturn\u001b[39;00m chunks\n\u001b[0;32m-> 1137\u001b[0m completion: Completion \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(completion_or_chunks)  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[39mreturn\u001b[39;00m completion\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/llama_cpp/llama.py:756\u001b[0m, in \u001b[0;36mLlama._create_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor)\u001b[0m\n\u001b[1;32m    754\u001b[0m finish_reason \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlength\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    755\u001b[0m multibyte_fix \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 756\u001b[0m \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate(\n\u001b[1;32m    757\u001b[0m     prompt_tokens,\n\u001b[1;32m    758\u001b[0m     top_k\u001b[39m=\u001b[39mtop_k,\n\u001b[1;32m    759\u001b[0m     top_p\u001b[39m=\u001b[39mtop_p,\n\u001b[1;32m    760\u001b[0m     temp\u001b[39m=\u001b[39mtemperature,\n\u001b[1;32m    761\u001b[0m     tfs_z\u001b[39m=\u001b[39mtfs_z,\n\u001b[1;32m    762\u001b[0m     mirostat_mode\u001b[39m=\u001b[39mmirostat_mode,\n\u001b[1;32m    763\u001b[0m     mirostat_tau\u001b[39m=\u001b[39mmirostat_tau,\n\u001b[1;32m    764\u001b[0m     mirostat_eta\u001b[39m=\u001b[39mmirostat_eta,\n\u001b[1;32m    765\u001b[0m     frequency_penalty\u001b[39m=\u001b[39mfrequency_penalty,\n\u001b[1;32m    766\u001b[0m     presence_penalty\u001b[39m=\u001b[39mpresence_penalty,\n\u001b[1;32m    767\u001b[0m     repeat_penalty\u001b[39m=\u001b[39mrepeat_penalty,\n\u001b[1;32m    768\u001b[0m     stopping_criteria\u001b[39m=\u001b[39mstopping_criteria,\n\u001b[1;32m    769\u001b[0m     logits_processor\u001b[39m=\u001b[39mlogits_processor,\n\u001b[1;32m    770\u001b[0m ):\n\u001b[1;32m    771\u001b[0m     \u001b[39mif\u001b[39;00m token \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_token_eos:\n\u001b[1;32m    772\u001b[0m         text \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdetokenize(completion_tokens)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/llama_cpp/llama.py:591\u001b[0m, in \u001b[0;36mLlama.generate\u001b[0;34m(self, tokens, top_k, top_p, temp, repeat_penalty, reset, frequency_penalty, presence_penalty, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, logits_processor, stopping_criteria)\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset()\n\u001b[1;32m    590\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 591\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meval(tokens)\n\u001b[1;32m    592\u001b[0m     token \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample(\n\u001b[1;32m    593\u001b[0m         top_k\u001b[39m=\u001b[39mtop_k,\n\u001b[1;32m    594\u001b[0m         top_p\u001b[39m=\u001b[39mtop_p,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    603\u001b[0m         logits_processor\u001b[39m=\u001b[39mlogits_processor,\n\u001b[1;32m    604\u001b[0m     )\n\u001b[1;32m    605\u001b[0m     \u001b[39mif\u001b[39;00m stopping_criteria \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m stopping_criteria(\n\u001b[1;32m    606\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_ids\u001b[39m.\u001b[39mtolist(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_scores[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m    607\u001b[0m     ):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/llama_cpp/llama.py:320\u001b[0m, in \u001b[0;36mLlama.eval\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    318\u001b[0m n_past \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(n_ctx \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(batch), \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_ids))\n\u001b[1;32m    319\u001b[0m n_tokens \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(batch)\n\u001b[0;32m--> 320\u001b[0m return_code \u001b[39m=\u001b[39m llama_cpp\u001b[39m.\u001b[39;49mllama_eval(\n\u001b[1;32m    321\u001b[0m     ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mctx,\n\u001b[1;32m    322\u001b[0m     tokens\u001b[39m=\u001b[39;49m(llama_cpp\u001b[39m.\u001b[39;49mllama_token \u001b[39m*\u001b[39;49m \u001b[39mlen\u001b[39;49m(batch))(\u001b[39m*\u001b[39;49mbatch),\n\u001b[1;32m    323\u001b[0m     n_tokens\u001b[39m=\u001b[39;49mllama_cpp\u001b[39m.\u001b[39;49mc_int(n_tokens),\n\u001b[1;32m    324\u001b[0m     n_past\u001b[39m=\u001b[39;49mllama_cpp\u001b[39m.\u001b[39;49mc_int(n_past),\n\u001b[1;32m    325\u001b[0m     n_threads\u001b[39m=\u001b[39;49mllama_cpp\u001b[39m.\u001b[39;49mc_int(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_threads),\n\u001b[1;32m    326\u001b[0m )\n\u001b[1;32m    327\u001b[0m \u001b[39mif\u001b[39;00m return_code \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    328\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mllama_eval returned \u001b[39m\u001b[39m{\u001b[39;00mreturn_code\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/llama_cpp/llama_cpp.py:439\u001b[0m, in \u001b[0;36mllama_eval\u001b[0;34m(ctx, tokens, n_tokens, n_past, n_threads)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mllama_eval\u001b[39m(\n\u001b[1;32m    433\u001b[0m     ctx: llama_context_p,\n\u001b[1;32m    434\u001b[0m     tokens,  \u001b[39m# type: Array[llama_token]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    437\u001b[0m     n_threads: c_int,\n\u001b[1;32m    438\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[0;32m--> 439\u001b[0m     \u001b[39mreturn\u001b[39;00m _lib\u001b[39m.\u001b[39;49mllama_eval(ctx, tokens, n_tokens, n_past, n_threads)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "rewards = []\n",
    "observations = []\n",
    "actions_taken = []\n",
    "position_old = None\n",
    "\n",
    "for i_episode in range(2):\n",
    "    observation = env.reset()\n",
    "    print(f\"observation: {observation}\")\n",
    "    observations.append(observation)\n",
    "\n",
    "    episode_reward = 0\n",
    "    print(f\"episode_reward: {episode_reward}\")\n",
    "\n",
    "    # Loop over t timesteps \n",
    "    for t in range(5):\n",
    "\n",
    "        print(f\"=> TIMESTAMP [{t}]; EPISODE [{i_episode}]<=\")\n",
    "\n",
    "        # Set position ot the last index in observations\n",
    "        position = observations[-1][0]\n",
    "        print(f\"position: {position}\")\n",
    "\n",
    "        # Give the LLM some information about the current state of the game\n",
    "\n",
    "        if (position_old is not None) and (position_old != position):\n",
    "            # save observation\n",
    "            agent.save_observation(f\"you are in position {position}. You moved from position {position_old}. Your last action was {action_space[actions_taken[-1]]}.\")\n",
    "        elif position_old is None:\n",
    "        \n",
    "            agent.save_observation(f\"you are in position {position}. This is the start of the game.\")\n",
    "        else:\n",
    "            # save observation\n",
    "            agent.save_observation(f\"you are still in position {position}. You did not move. Your last action was {actions_taken[-1]}.\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(f\"saved observation: you are in position {position}\")\n",
    "\n",
    "        # generate action\n",
    "        action = agent.generate_action(debug=True)\n",
    "        print(\"selected action\", action)\n",
    "\n",
    "        # take action\n",
    "        # Within the game board state\n",
    "        # \n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "        print(\"GENERATED ACTION: \", action)\n",
    "        print(\"RENEDERED ACTION: \", env.render())\n",
    "\n",
    "\n",
    "        print(\"--------------------\")\n",
    "        print(f\"obs: {obs}\")\n",
    "        print(f\"reward: {reward}\")\n",
    "        print(f\"terminated: {terminated}\")\n",
    "        print(f\"truncated: {truncated}\")\n",
    "        print(f\"info: {info}\")\n",
    "        print(\"--------------------\")\n",
    "\n",
    "        observations.append((obs, info))\n",
    "\n",
    "        # save reward\n",
    "        agent.save_reward(reward)\n",
    "\n",
    "        position_old = position\n",
    "\n",
    "        actions_taken.append(action)\n",
    "\n",
    "        # If the episode terminated prematurely, save the reward and stop the episode\n",
    "        if terminated:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            rewards.append(reward)\n",
    "            break\n",
    "\n",
    "        if t == 9:\n",
    "            rewards.append(reward)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f961e878700>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGdCAYAAADuR1K7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAfzklEQVR4nO3de3DU1f3/8VcuZINKErllCS4iFAUFzZiYENThW8k0FkbNiCMiBaSp1ArUEopyk7RajfWKCspga6kjFIpVRjETi8E7K2CAVq7VgoDQXaBIFkGSkJzfHwzrLxowSdkN+/b5mNlx+Ow5u+dzBPfpJ7tLnHPOCQAAwIj41l4AAADA6UTcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwJTE1l5Aa6ivr9eePXvUrl07xcXFtfZyAABAEzjndOjQIWVkZCg+/uTXZ76XcbNnzx75fL7WXgYAAGiBXbt26bzzzjvp/d/LuGnXrp2k45uTkpLSyqsBAABNEQqF5PP5wq/jJ/O9jJsTP4pKSUkhbgAAiDHf9ZYS3lAMAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADAlKnEzZ84cde/eXcnJycrNzdXq1atPOX7JkiXq3bu3kpOT1a9fP5WVlZ107B133KG4uDjNmjXrNK8aAADEoojHzeLFi1VcXKySkhKtXbtWl112mQoKCrR3795Gx69cuVLDhw9XUVGR1q1bp8LCQhUWFmrDhg3fGvvKK6/oww8/VEZGRqRPAwAAxIiIx83jjz+u22+/XWPGjNHFF1+suXPn6qyzztLzzz/f6Pgnn3xS1157rSZPnqw+ffro/vvv1+WXX67Zs2c3GLd7925NmDBBCxYsUJs2bSJ9GgAAIEZENG5qampUWVmp/Pz8r58wPl75+fny+/2NzvH7/Q3GS1JBQUGD8fX19Ro5cqQmT56sSy655DvXUV1drVAo1OAGAABsimjc7N+/X3V1dUpPT29wPD09XYFAoNE5gUDgO8f//ve/V2Jion75y182aR2lpaVKTU0N33w+XzPPBAAAxIqY+7RUZWWlnnzySc2fP19xcXFNmjN16lRVVVWFb7t27YrwKgEAQGuJaNx07NhRCQkJCgaDDY4Hg0F5vd5G53i93lOOf++997R3715169ZNiYmJSkxM1I4dOzRp0iR179690cf0eDxKSUlpcAMAADZFNG6SkpKUlZWlioqK8LH6+npVVFQoLy+v0Tl5eXkNxkvS8uXLw+NHjhypf/7zn1q/fn34lpGRocmTJ+uNN96I3MkAAICYkBjpJyguLtbo0aOVnZ2tnJwczZo1S4cPH9aYMWMkSaNGjVLXrl1VWloqSbrrrrs0cOBAPfbYYxoyZIgWLVqkjz76SPPmzZMkdejQQR06dGjwHG3atJHX69VFF10U6dMBAABnuIjHzbBhw7Rv3z7NnDlTgUBAmZmZKi8vD79peOfOnYqP//oC0oABA7Rw4ULNmDFD06ZNU69evbR06VL17ds30ksFAAAGxDnnXGsvItpCoZBSU1NVVVXF+28AAIgRTX39jrlPSwEAAJwKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTohI3c+bMUffu3ZWcnKzc3FytXr36lOOXLFmi3r17Kzk5Wf369VNZWVn4vtraWt1zzz3q16+fzj77bGVkZGjUqFHas2dPpE8DAADEgIjHzeLFi1VcXKySkhKtXbtWl112mQoKCrR3795Gx69cuVLDhw9XUVGR1q1bp8LCQhUWFmrDhg2SpCNHjmjt2rW69957tXbtWr388svaunWrrr/++kifCgAAiAFxzjkXySfIzc3VFVdcodmzZ0uS6uvr5fP5NGHCBE2ZMuVb44cNG6bDhw9r2bJl4WP9+/dXZmam5s6d2+hzrFmzRjk5OdqxY4e6dev2nWsKhUJKTU1VVVWVUlJSWnhmAAAgmpr6+h3RKzc1NTWqrKxUfn7+108YH6/8/Hz5/f5G5/j9/gbjJamgoOCk4yWpqqpKcXFxSktLa/T+6upqhUKhBjcAAGBTRONm//79qqurU3p6eoPj6enpCgQCjc4JBALNGn/06FHdc889Gj58+EkrrrS0VKmpqeGbz+drwdkAAIBYENOflqqtrdXNN98s55yeffbZk46bOnWqqqqqwrddu3ZFcZUAACCaEiP54B07dlRCQoKCwWCD48FgUF6vt9E5Xq+3SeNPhM2OHTu0YsWKU/7szePxyOPxtPAsAABALInolZukpCRlZWWpoqIifKy+vl4VFRXKy8trdE5eXl6D8ZK0fPnyBuNPhM0nn3yiN998Ux06dIjMCQAAgJgT0Ss3klRcXKzRo0crOztbOTk5mjVrlg4fPqwxY8ZIkkaNGqWuXbuqtLRUknTXXXdp4MCBeuyxxzRkyBAtWrRIH330kebNmyfpeNjcdNNNWrt2rZYtW6a6urrw+3Hat2+vpKSkSJ8SAAA4g0U8boYNG6Z9+/Zp5syZCgQCyszMVHl5efhNwzt37lR8/NcXkAYMGKCFCxdqxowZmjZtmnr16qWlS5eqb9++kqTdu3fr1VdflSRlZmY2eK633npL//d//xfpUwIAAGewiH/PzZmI77kBACD2nBHfcwMAABBtxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMIW4AAIApxA0AADCFuAEAAKYQNwAAwBTiBgAAmELcAAAAU4gbAABgCnEDAABMiUrczJkzR927d1dycrJyc3O1evXqU45fsmSJevfureTkZPXr109lZWUN7nfOaebMmerSpYvatm2r/Px8ffLJJ5E8BQAAECMiHjeLFy9WcXGxSkpKtHbtWl122WUqKCjQ3r17Gx2/cuVKDR8+XEVFRVq3bp0KCwtVWFioDRs2hMc8/PDDeuqppzR37lytWrVKZ599tgoKCnT06NFInw4AADjDxTnnXCSfIDc3V1dccYVmz54tSaqvr5fP59OECRM0ZcqUb40fNmyYDh8+rGXLloWP9e/fX5mZmZo7d66cc8rIyNCkSZP061//WpJUVVWl9PR0zZ8/X7fccst3rikUCik1NVVVVVVKSUk5TWd6/IrSV7V1p+3xAACIVW3bJCguLu60PmZTX78TT+uzfkNNTY0qKys1derU8LH4+Hjl5+fL7/c3Osfv96u4uLjBsYKCAi1dulSStH37dgUCAeXn54fvT01NVW5urvx+f6NxU11drerq6vCvQ6HQ/3JaJ/VVbZ0unvlGRB4bAIBYsum+Ap2VFNHMOKmI/lhq//79qqurU3p6eoPj6enpCgQCjc4JBAKnHH/in815zNLSUqWmpoZvPp+vRecDAADOfK2TVFE2derUBleDQqFQRAKnbZsEbbqv4LQ/LgAAsaZtm4RWe+6Ixk3Hjh2VkJCgYDDY4HgwGJTX6210jtfrPeX4E/8MBoPq0qVLgzGZmZmNPqbH45HH42npaTRZXFxcq12CAwAAx0X0x1JJSUnKyspSRUVF+Fh9fb0qKiqUl5fX6Jy8vLwG4yVp+fLl4fEXXHCBvF5vgzGhUEirVq066WMCAIDvj4hfZiguLtbo0aOVnZ2tnJwczZo1S4cPH9aYMWMkSaNGjVLXrl1VWloqSbrrrrs0cOBAPfbYYxoyZIgWLVqkjz76SPPmzZN0/OrIr371K/3ud79Tr169dMEFF+jee+9VRkaGCgsLI306AADgDBfxuBk2bJj27dunmTNnKhAIKDMzU+Xl5eE3BO/cuVPx8V9fQBowYIAWLlyoGTNmaNq0aerVq5eWLl2qvn37hsfcfffdOnz4sMaOHauDBw/qqquuUnl5uZKTkyN9OgAA4AwX8e+5ORNF6ntuAABA5DT19Zu/WwoAAJhC3AAAAFOIGwAAYApxAwAATCFuAACAKcQNAAAwhbgBAACmEDcAAMAU4gYAAJhC3AAAAFOIGwAAYApxAwAATCFuAACAKcQNAAAwhbgBAACmEDcAAMAU4gYAAJhC3AAAAFOIGwAAYApxAwAATCFuAACAKcQNAAAwhbgBAACmEDcAAMAU4gYAAJhC3AAAAFOIGwAAYApxAwAATCFuAACAKcQNAAAwhbgBAACmEDcAAMAU4gYAAJhC3AAAAFOIGwAAYApxAwAATCFuAACAKcQNAAAwhbgBAACmEDcAAMAU4gYAAJhC3AAAAFOIGwAAYApxAwAATCFuAACAKcQNAAAwhbgBAACmEDcAAMAU4gYAAJhC3AAAAFOIGwAAYApxAwAATCFuAACAKcQNAAAwhbgBAACmEDcAAMCUiMXNgQMHNGLECKWkpCgtLU1FRUX68ssvTznn6NGjGjdunDp06KBzzjlHQ4cOVTAYDN//j3/8Q8OHD5fP51Pbtm3Vp08fPfnkk5E6BQAAEIMiFjcjRozQxo0btXz5ci1btkzvvvuuxo4de8o5EydO1GuvvaYlS5bonXfe0Z49e3TjjTeG76+srFTnzp314osvauPGjZo+fbqmTp2q2bNnR+o0AABAjIlzzrnT/aCbN2/WxRdfrDVr1ig7O1uSVF5ersGDB+vzzz9XRkbGt+ZUVVWpU6dOWrhwoW666SZJ0pYtW9SnTx/5/X7179+/0ecaN26cNm/erBUrVjR5faFQSKmpqaqqqlJKSkoLzhAAAERbU1+/I3Llxu/3Ky0tLRw2kpSfn6/4+HitWrWq0TmVlZWqra1Vfn5++Fjv3r3VrVs3+f3+kz5XVVWV2rdvf/oWDwAAYlpiJB40EAioc+fODZ8oMVHt27dXIBA46ZykpCSlpaU1OJ6enn7SOStXrtTixYv1+uuvn3I91dXVqq6uDv86FAo14SwAAEAsataVmylTpiguLu6Uty1btkRqrQ1s2LBBN9xwg0pKSvSjH/3olGNLS0uVmpoavvl8vqisEQAARF+zrtxMmjRJt9122ynH9OjRQ16vV3v37m1w/NixYzpw4IC8Xm+j87xer2pqanTw4MEGV2+CweC35mzatEmDBg3S2LFjNWPGjO9c99SpU1VcXBz+dSgUInAAADCqWXHTqVMnderU6TvH5eXl6eDBg6qsrFRWVpYkacWKFaqvr1dubm6jc7KystSmTRtVVFRo6NChkqStW7dq586dysvLC4/buHGjrrnmGo0ePVoPPPBAk9bt8Xjk8XiaNBYAAMS2iHxaSpJ+/OMfKxgMau7cuaqtrdWYMWOUnZ2thQsXSpJ2796tQYMG6YUXXlBOTo4k6Re/+IXKyso0f/58paSkaMKECZKOv7dGOv6jqGuuuUYFBQV65JFHws+VkJDQpOg6gU9LAQAQe5r6+h2RNxRL0oIFCzR+/HgNGjRI8fHxGjp0qJ566qnw/bW1tdq6dauOHDkSPvbEE0+Ex1ZXV6ugoEDPPPNM+P6XXnpJ+/bt04svvqgXX3wxfPz888/XZ599FqlTAQAAMSRiV27OZFy5AQAg9rTq99wAAAC0FuIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAlIjFzYEDBzRixAilpKQoLS1NRUVF+vLLL0855+jRoxo3bpw6dOigc845R0OHDlUwGGx07H//+1+dd955iouL08GDByNwBgAAIBZFLG5GjBihjRs3avny5Vq2bJneffddjR079pRzJk6cqNdee01LlizRO++8oz179ujGG29sdGxRUZEuvfTSSCwdAADEsDjnnDvdD7p582ZdfPHFWrNmjbKzsyVJ5eXlGjx4sD7//HNlZGR8a05VVZU6deqkhQsX6qabbpIkbdmyRX369JHf71f//v3DY5999lktXrxYM2fO1KBBg/TFF18oLS2tyesLhUJKTU1VVVWVUlJS/reTBQAAUdHU1++IXLnx+/1KS0sLh40k5efnKz4+XqtWrWp0TmVlpWpra5Wfnx8+1rt3b3Xr1k1+vz98bNOmTbrvvvv0wgsvKD6+acuvrq5WKBRqcAMAADZFJG4CgYA6d+7c4FhiYqLat2+vQCBw0jlJSUnfugKTnp4enlNdXa3hw4frkUceUbdu3Zq8ntLSUqWmpoZvPp+veScEAABiRrPiZsqUKYqLizvlbcuWLZFaq6ZOnao+ffroJz/5SbPnVVVVhW+7du2K0AoBAEBrS2zO4EmTJum222475ZgePXrI6/Vq7969DY4fO3ZMBw4ckNfrbXSe1+tVTU2NDh482ODqTTAYDM9ZsWKFPv74Y7300kuSpBNvF+rYsaOmT5+u3/72t40+tsfjkcfjacopAgCAGNesuOnUqZM6der0nePy8vJ08OBBVVZWKisrS9LxMKmvr1dubm6jc7KystSmTRtVVFRo6NChkqStW7dq586dysvLkyT97W9/01dffRWes2bNGv30pz/Ve++9p549ezbnVAAAgFHNipum6tOnj6699lrdfvvtmjt3rmprazV+/Hjdcsst4U9K7d69W4MGDdILL7ygnJwcpaamqqioSMXFxWrfvr1SUlI0YcIE5eXlhT8p9c2A2b9/f/j5mvNpKQAAYFdE4kaSFixYoPHjx2vQoEGKj4/X0KFD9dRTT4Xvr62t1datW3XkyJHwsSeeeCI8trq6WgUFBXrmmWcitUQAAGBQRL7n5kzH99wAABB7WvV7bgAAAFoLcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAExJbO0FtAbnnCQpFAq18koAAEBTnXjdPvE6fjLfy7g5dOiQJMnn87XySgAAQHMdOnRIqampJ70/zn1X/hhUX1+vPXv2qF27doqLizutjx0KheTz+bRr1y6lpKSc1sfG19jn6GCfo4N9jg72OToiuc/OOR06dEgZGRmKjz/5O2u+l1du4uPjdd5550X0OVJSUvjDEwXsc3Swz9HBPkcH+xwdkdrnU12xOYE3FAMAAFOIGwAAYApxc5p5PB6VlJTI4/G09lJMY5+jg32ODvY5Otjn6DgT9vl7+YZiAABgF1duAACAKcQNAAAwhbgBAACmEDcAAMAU4qaZ5syZo+7duys5OVm5ublavXr1KccvWbJEvXv3VnJysvr166eysrIorTT2NWevn3vuOV199dU699xzde655yo/P/87/93guOb+nj5h0aJFiouLU2FhYWQXaERz9/ngwYMaN26cunTpIo/HowsvvJD/fjRBc/d51qxZuuiii9S2bVv5fD5NnDhRR48ejdJqY9O7776r6667ThkZGYqLi9PSpUu/c87bb7+tyy+/XB6PRz/4wQ80f/78yC7SockWLVrkkpKS3PPPP+82btzobr/9dpeWluaCwWCj4z/44AOXkJDgHn74Ybdp0yY3Y8YM16ZNG/fxxx9HeeWxp7l7feutt7o5c+a4devWuc2bN7vbbrvNpaamus8//zzKK48tzd3nE7Zv3+66du3qrr76anfDDTdEZ7ExrLn7XF1d7bKzs93gwYPd+++/77Zv3+7efvttt379+iivPLY0d58XLFjgPB6PW7Bggdu+fbt74403XJcuXdzEiROjvPLYUlZW5qZPn+5efvllJ8m98sorpxy/bds2d9ZZZ7ni4mK3adMm9/TTT7uEhARXXl4esTUSN82Qk5Pjxo0bF/51XV2dy8jIcKWlpY2Ov/nmm92QIUMaHMvNzXU///nPI7pOC5q719907Ngx165dO/fnP/85Uks0oSX7fOzYMTdgwAD3hz/8wY0ePZq4aYLm7vOzzz7revTo4WpqaqK1RBOau8/jxo1z11xzTYNjxcXF7sorr4zoOi1pStzcfffd7pJLLmlwbNiwYa6goCBi6+LHUk1UU1OjyspK5efnh4/Fx8crPz9ffr+/0Tl+v7/BeEkqKCg46Xgc15K9/qYjR46otrZW7du3j9QyY15L9/m+++5T586dVVRUFI1lxryW7POrr76qvLw8jRs3Tunp6erbt68efPBB1dXVRWvZMacl+zxgwABVVlaGf3S1bds2lZWVafDgwVFZ8/dFa7wWfi//4syW2L9/v+rq6pSent7geHp6urZs2dLonEAg0Oj4QCAQsXVa0JK9/qZ77rlHGRkZ3/oDha+1ZJ/ff/99/fGPf9T69eujsEIbWrLP27Zt04oVKzRixAiVlZXp008/1Z133qna2lqVlJREY9kxpyX7fOutt2r//v266qqr5JzTsWPHdMcdd2jatGnRWPL3xsleC0OhkL766iu1bdv2tD8nV25gzkMPPaRFixbplVdeUXJycmsvx4xDhw5p5MiReu6559SxY8fWXo5p9fX16ty5s+bNm6esrCwNGzZM06dP19y5c1t7aaa8/fbbevDBB/XMM89o7dq1evnll/X666/r/vvvb+2l4X/ElZsm6tixoxISEhQMBhscDwaD8nq9jc7xer3NGo/jWrLXJzz66KN66KGH9Oabb+rSSy+N5DJjXnP3+d///rc+++wzXXfddeFj9fX1kqTExERt3bpVPXv2jOyiY1BLfj936dJFbdq0UUJCQvhYnz59FAgEVFNTo6SkpIiuORa1ZJ/vvfdejRw5Uj/72c8kSf369dPhw4c1duxYTZ8+XfHx/P//6XCy18KUlJSIXLWRuHLTZElJScrKylJFRUX4WH19vSoqKpSXl9fonLy8vAbjJWn58uUnHY/jWrLXkvTwww/r/vvvV3l5ubKzs6Ox1JjW3H3u3bu3Pv74Y61fvz58u/766/XDH/5Q69evl8/ni+byY0ZLfj9feeWV+vTTT8PxKEn/+te/1KVLF8LmJFqyz0eOHPlWwJwISsdfu3jatMprYcTeqmzQokWLnMfjcfPnz3ebNm1yY8eOdWlpaS4QCDjnnBs5cqSbMmVKePwHH3zgEhMT3aOPPuo2b97sSkpK+Ch4EzV3rx966CGXlJTkXnrpJfef//wnfDt06FBrnUJMaO4+fxOflmqa5u7zzp07Xbt27dz48ePd1q1b3bJly1znzp3d7373u9Y6hZjQ3H0uKSlx7dq1c3/5y1/ctm3b3N///nfXs2dPd/PNN7fWKcSEQ4cOuXXr1rl169Y5Se7xxx9369atczt27HDOOTdlyhQ3cuTI8PgTHwWfPHmy27x5s5szZw4fBT/TPP30065bt24uKSnJ5eTkuA8//DB838CBA93o0aMbjP/rX//qLrzwQpeUlOQuueQS9/rrr0d5xbGrOXt9/vnnO0nfupWUlER/4TGmub+n/3/ETdM1d59XrlzpcnNzncfjcT169HAPPPCAO3bsWJRXHXuas8+1tbXuN7/5jevZs6dLTk52Pp/P3Xnnne6LL76I/sJjyFtvvdXof29P7O3o0aPdwIEDvzUnMzPTJSUluR49erg//elPEV1jnHNcewMAAHbwnhsAAGAKcQMAAEwhbgAAgCnEDQAAMIW4AQAAphA3AADAFOIGAACYQtwAAABTiBsAAGAKcQMAAEwhbgAAgCnEDQAAMOX/AVQlbz/chw3yAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(rewards)\n",
    "plt.plot(rewards)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
